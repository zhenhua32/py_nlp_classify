{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 624/624 [00:00<00:00, 325kB/s]\n",
      "Downloading: 100%|██████████| 393M/393M [00:22<00:00, 18.6MB/s] \n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "pretrain_model_name = \"bert-base-chinese\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrain_model_name, num_labels=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 14.8kB/s]\n",
      "Downloading: 100%|██████████| 107k/107k [00:01<00:00, 79.9kB/s] \n",
      "Downloading: 100%|██████████| 263k/263k [00:04<00:00, 58.0kB/s] \n"
     ]
    }
   ],
   "source": [
    "# 定义分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrain_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ad69658844a650a2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\zhenh\\.cache\\huggingface\\datasets\\csv\\default-ad69658844a650a2\\0.0.0\\6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\zhenh\\.cache\\huggingface\\datasets\\csv\\default-ad69658844a650a2\\0.0.0\\6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 153.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# 从本地加载数据\n",
    "# 标签名要命名为 labels\n",
    "raw_dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\"train\": \"./data/train.csv\", \"dev\": \"./data/dev.csv\"},\n",
    "    delimiter=\"\\t\",\n",
    "    column_names=[\"str_label\", \"text\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:03<00:00, 13.58ba/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.46ba/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "# 分词\n",
    "tokenized_datasets = raw_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样的, 将文本标签转换成整数\n",
    "label_map = {\n",
    "    \"agriculture\": 0,\n",
    "    \"house\": 1,\n",
    "    \"game\": 2,\n",
    "    \"sports\": 3,\n",
    "    \"entertainment\": 4,\n",
    "    \"story\": 5,\n",
    "    \"car\": 6,\n",
    "    \"culture\": 7,\n",
    "    \"finance\": 8,\n",
    "    \"edu\": 9,\n",
    "    \"military\": 10,\n",
    "    \"travel\": 11,\n",
    "    \"stock\": 12,\n",
    "    \"world\": 13,\n",
    "    \"tech\": 14,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53360/53360 [00:22<00:00, 2410.63ex/s]\n",
      "100%|██████████| 10000/10000 [00:04<00:00, 2422.78ex/s]\n"
     ]
    }
   ],
   "source": [
    "def label_function(ex):\n",
    "    ex[\"labels\"] = label_map[ex[\"str_label\"]]\n",
    "    return ex\n",
    "\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(label_function, batched=False)\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "dev_dataset = tokenized_datasets[\"dev\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载评估器\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\"test_trainer_pt\", evaluation_strategy=\"epoch\", report_to=\"none\", save_total_limit=2,)\n",
    "\n",
    "# 定义训练器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, str_label.\n",
      "***** Running training *****\n",
      "  Num examples = 53360\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20010\n",
      "  2%|▏         | 500/20010 [02:58<1:54:11,  2.85it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6087, 'learning_rate': 4.8750624687656176e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-500\\pytorch_model.bin\n",
      "  5%|▍         | 1000/20010 [05:53<1:48:41,  2.92it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-1000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3419, 'learning_rate': 4.750124937531234e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-1000\\pytorch_model.bin\n",
      "  7%|▋         | 1500/20010 [08:47<1:46:03,  2.91it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-1500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.332, 'learning_rate': 4.625187406296852e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-500] due to args.save_total_limit\n",
      " 10%|▉         | 2000/20010 [11:41<1:43:02,  2.91it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-2000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2143, 'learning_rate': 4.500249875062469e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-1000] due to args.save_total_limit\n",
      " 12%|█▏        | 2500/20010 [14:35<1:42:47,  2.84it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-2500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-2500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2348, 'learning_rate': 4.3753123438280864e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-1500] due to args.save_total_limit\n",
      " 15%|█▍        | 3000/20010 [17:30<1:37:38,  2.90it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-3000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-3000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1993, 'learning_rate': 4.250374812593703e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-2000] due to args.save_total_limit\n",
      " 17%|█▋        | 3500/20010 [20:26<1:35:07,  2.89it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-3500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-3500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1875, 'learning_rate': 4.1254372813593204e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-2500] due to args.save_total_limit\n",
      " 20%|█▉        | 4000/20010 [23:20<1:30:53,  2.94it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-4000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-4000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1409, 'learning_rate': 4.000499750124938e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-3000] due to args.save_total_limit\n",
      " 22%|██▏       | 4500/20010 [26:18<1:34:04,  2.75it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-4500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-4500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1763, 'learning_rate': 3.875562218890555e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-3500] due to args.save_total_limit\n",
      " 25%|██▍       | 5000/20010 [29:24<1:32:01,  2.72it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-5000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-5000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1595, 'learning_rate': 3.7506246876561725e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-4000] due to args.save_total_limit\n",
      " 27%|██▋       | 5500/20010 [32:28<1:26:27,  2.80it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-5500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-5500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1172, 'learning_rate': 3.625687156421789e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-5500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-4500] due to args.save_total_limit\n",
      " 30%|██▉       | 6000/20010 [8:35:26<1:23:51,  2.78it/s]      Saving model checkpoint to test_trainer_pt\\checkpoint-6000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-6000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1163, 'learning_rate': 3.5007496251874065e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-5000] due to args.save_total_limit\n",
      " 32%|███▏      | 6500/20010 [8:38:25<1:17:43,  2.90it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-6500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-6500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1284, 'learning_rate': 3.375812093953024e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-5500] due to args.save_total_limit\n",
      " 33%|███▎      | 6670/20010 [8:39:14<1:23:11,  2.67it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, str_label.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n",
      "                                                        \n",
      " 33%|███▎      | 6670/20010 [8:41:31<1:23:11,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0625436305999756, 'eval_accuracy': 0.6291, 'eval_runtime': 136.8999, 'eval_samples_per_second': 73.046, 'eval_steps_per_second': 9.131, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 7000/20010 [8:43:25<1:13:54,  2.93it/s]  Saving model checkpoint to test_trainer_pt\\checkpoint-7000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-7000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9627, 'learning_rate': 3.250874562718641e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-7000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-6000] due to args.save_total_limit\n",
      " 37%|███▋      | 7500/20010 [8:46:20<1:13:39,  2.83it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-7500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-7500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9204, 'learning_rate': 3.125937031484258e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-7500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-6500] due to args.save_total_limit\n",
      " 40%|███▉      | 8000/20010 [8:49:16<1:09:26,  2.88it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-8000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-8000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9289, 'learning_rate': 3.0009995002498753e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-8000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-7000] due to args.save_total_limit\n",
      " 42%|████▏     | 8500/20010 [8:52:11<1:07:24,  2.85it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-8500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-8500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.857, 'learning_rate': 2.8760619690154923e-05, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-8500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-7500] due to args.save_total_limit\n",
      " 45%|████▍     | 9000/20010 [8:55:10<1:04:23,  2.85it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-9000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-9000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9066, 'learning_rate': 2.7511244377811096e-05, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-9000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-8000] due to args.save_total_limit\n",
      " 47%|████▋     | 9500/20010 [8:58:08<1:02:27,  2.80it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-9500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-9500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9171, 'learning_rate': 2.6261869065467267e-05, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-9500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-8500] due to args.save_total_limit\n",
      " 50%|████▉     | 10000/20010 [9:01:01<58:40,  2.84it/s] Saving model checkpoint to test_trainer_pt\\checkpoint-10000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-10000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9091, 'learning_rate': 2.501249375312344e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-10000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-9000] due to args.save_total_limit\n",
      " 52%|█████▏    | 10500/20010 [9:03:57<53:42,  2.95it/s]  Saving model checkpoint to test_trainer_pt\\checkpoint-10500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-10500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8899, 'learning_rate': 2.376311844077961e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-10500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-9500] due to args.save_total_limit\n",
      " 55%|█████▍    | 11000/20010 [9:06:52<53:57,  2.78it/s]  Saving model checkpoint to test_trainer_pt\\checkpoint-11000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-11000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8722, 'learning_rate': 2.2513743128435784e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-11000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-10000] due to args.save_total_limit\n",
      " 57%|█████▋    | 11500/20010 [9:09:49<48:31,  2.92it/s]  Saving model checkpoint to test_trainer_pt\\checkpoint-11500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-11500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8536, 'learning_rate': 2.1264367816091954e-05, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-11500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-10500] due to args.save_total_limit\n",
      " 60%|█████▉    | 12000/20010 [9:11:20<22:20,  5.98it/s]  Saving model checkpoint to test_trainer_pt\\checkpoint-12000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-12000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.905, 'learning_rate': 2.0014992503748124e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-12000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-11000] due to args.save_total_limit\n",
      " 62%|██████▏   | 12500/20010 [9:12:47<21:34,  5.80it/s]  Saving model checkpoint to test_trainer_pt\\checkpoint-12500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-12500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8756, 'learning_rate': 1.87656171914043e-05, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-12500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-11500] due to args.save_total_limit\n",
      " 65%|██████▍   | 13000/20010 [9:14:13<19:45,  5.91it/s]  Saving model checkpoint to test_trainer_pt\\checkpoint-13000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-13000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8022, 'learning_rate': 1.751624187906047e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-13000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-12000] due to args.save_total_limit\n",
      " 67%|██████▋   | 13340/20010 [9:15:13<19:08,  5.81it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, str_label.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n",
      "                                                       \n",
      " 67%|██████▋   | 13341/20010 [9:16:20<37:42:02, 20.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0087946653366089, 'eval_accuracy': 0.6543, 'eval_runtime': 67.2573, 'eval_samples_per_second': 148.683, 'eval_steps_per_second': 18.585, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 13500/20010 [9:16:48<18:21,  5.91it/s]   Saving model checkpoint to test_trainer_pt\\checkpoint-13500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-13500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7598, 'learning_rate': 1.626686656671664e-05, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-13500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-12500] due to args.save_total_limit\n",
      " 70%|██████▉   | 14000/20010 [9:18:15<16:58,  5.90it/s]  Saving model checkpoint to test_trainer_pt\\checkpoint-14000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-14000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.596, 'learning_rate': 1.5017491254372815e-05, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-14000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-13000] due to args.save_total_limit\n",
      " 72%|███████▏  | 14500/20010 [9:19:42<15:13,  6.03it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-14500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-14500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6202, 'learning_rate': 1.3768115942028985e-05, 'epoch': 2.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-14500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-13500] due to args.save_total_limit\n",
      " 75%|███████▍  | 15000/20010 [9:21:09<14:26,  5.78it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-15000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-15000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6022, 'learning_rate': 1.2518740629685157e-05, 'epoch': 2.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-15000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-14000] due to args.save_total_limit\n",
      " 77%|███████▋  | 15500/20010 [9:22:35<12:51,  5.85it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-15500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-15500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5953, 'learning_rate': 1.126936531734133e-05, 'epoch': 2.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-15500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-14500] due to args.save_total_limit\n",
      " 80%|███████▉  | 16000/20010 [9:24:01<11:16,  5.93it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-16000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-16000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5702, 'learning_rate': 1.0019990004997503e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-16000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-15000] due to args.save_total_limit\n",
      " 82%|████████▏ | 16500/20010 [9:25:27<09:53,  5.91it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-16500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-16500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5653, 'learning_rate': 8.770614692653675e-06, 'epoch': 2.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-16500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-15500] due to args.save_total_limit\n",
      " 85%|████████▍ | 17000/20010 [9:26:53<08:20,  6.02it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-17000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-17000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5846, 'learning_rate': 7.521239380309846e-06, 'epoch': 2.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-17000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-16000] due to args.save_total_limit\n",
      " 87%|████████▋ | 17500/20010 [9:28:19<07:08,  5.85it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-17500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-17500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.544, 'learning_rate': 6.271864067966017e-06, 'epoch': 2.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-17500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-16500] due to args.save_total_limit\n",
      " 90%|████████▉ | 18000/20010 [9:29:45<05:40,  5.90it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-18000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-18000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5681, 'learning_rate': 5.0224887556221895e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-18000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-17000] due to args.save_total_limit\n",
      " 92%|█████████▏| 18500/20010 [9:31:11<04:19,  5.82it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-18500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-18500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5644, 'learning_rate': 3.773113443278361e-06, 'epoch': 2.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-18500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-17500] due to args.save_total_limit\n",
      " 95%|█████████▍| 19000/20010 [9:32:37<02:50,  5.93it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-19000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-19000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5778, 'learning_rate': 2.523738130934533e-06, 'epoch': 2.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-19000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-18000] due to args.save_total_limit\n",
      " 97%|█████████▋| 19500/20010 [9:34:03<01:25,  5.97it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-19500\n",
      "Configuration saved in test_trainer_pt\\checkpoint-19500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5767, 'learning_rate': 1.2743628185907047e-06, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-19500\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-18500] due to args.save_total_limit\n",
      "100%|█████████▉| 20000/20010 [9:35:29<00:01,  5.82it/s]Saving model checkpoint to test_trainer_pt\\checkpoint-20000\n",
      "Configuration saved in test_trainer_pt\\checkpoint-20000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5392, 'learning_rate': 2.4987506246876563e-08, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer_pt\\checkpoint-20000\\pytorch_model.bin\n",
      "Deleting older checkpoint [test_trainer_pt\\checkpoint-19000] due to args.save_total_limit\n",
      "100%|██████████| 20010/20010 [9:35:32<00:00,  5.46it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, str_label.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n",
      "                                                       \n",
      "100%|██████████| 20010/20010 [9:36:38<00:00,  5.46it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 20010/20010 [9:36:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1006031036376953, 'eval_accuracy': 0.66, 'eval_runtime': 66.0549, 'eval_samples_per_second': 151.389, 'eval_steps_per_second': 18.924, 'epoch': 3.0}\n",
      "{'train_runtime': 34598.8993, 'train_samples_per_second': 4.627, 'train_steps_per_second': 0.578, 'train_loss': 0.8953476309359282, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20010, training_loss=0.8953476309359282, metrics={'train_runtime': 34598.8993, 'train_samples_per_second': 4.627, 'train_steps_per_second': 0.578, 'train_loss': 0.8953476309359282, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e2a1ac0cd441cd5e6071952e5fb90a282373ff6bf90167c932fd3386a58db77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
